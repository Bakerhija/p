{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOfHnX+GnMy1eCglBbpagCQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smabb/p/blob/master/Lesson6%20Pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PP5OHO_HLPU",
        "colab_type": "text"
      },
      "source": [
        "<!--NAVIGATION-->\n",
        "\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/smabb/p/blob/master/Lesson6 Pandas.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltf9JhvRHLPa",
        "colab_type": "text"
      },
      "source": [
        "# Pandas\n",
        "\n",
        "In the NumPy section we dealt with some arrays, whose columns had each a special meaning. For example, the column number 0 could contain values interpreted as years, and column 1 could contain a month, and so on. It is possible to handle the data this way, but in can be hard to remember, which column number corresponds to which variable. Especially, if you later remove some column from the array, then the numbering of the remaining columns changes. One solution to this is to give a descriptive name to each column. These column names stay fixed and attached to their corresponding columns, even if we remove some of the columns. In addition, the rows can be given names as well, these are called *indices* in Pandas.\n",
        "\n",
        "The [Pandas](http://pandas.pydata.org/) library is built on top of the NumPy library, and it provides a special kind of two dimensional data structure called `DataFrame`. The `DataFrame` allows to give names to the columns, so that one can access a column using its name in place of the index of the column.\n",
        "\n",
        "First we will quickly go through a few examples to see what is possible with Pandas. You may need to check some details from the Pandas [documentation](http://pandas.pydata.org/pandas-docs/stable/) in order to complete the exercises. We start by doing some standard imports:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yf28kbnoHLPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd    # This is the standard way of importing the Pandas library\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgYK8elOHLPr",
        "colab_type": "text"
      },
      "source": [
        "Let's import some weather data that is in text form in a csv (Commma Separated Values) file. The following call will fetch the data from the internet and convert it to a DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZaRAtcBHLPw",
        "colab_type": "code",
        "outputId": "613b5bcf-5630-444d-c326-392866e9962c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "wh = pd.read_csv(\"https://raw.githubusercontent.com/smabb/p/master/data/temp.csv\")\n",
        "wh.head()   # The head method prints the first 5 rows"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>m</th>\n",
              "      <th>d</th>\n",
              "      <th>Time</th>\n",
              "      <th>Time zone</th>\n",
              "      <th>Precipitation amount (mm)</th>\n",
              "      <th>Snow depth (cm)</th>\n",
              "      <th>Air temperature (degC)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>00:00</td>\n",
              "      <td>UTC</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>00:00</td>\n",
              "      <td>UTC</td>\n",
              "      <td>4.4</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-3.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>00:00</td>\n",
              "      <td>UTC</td>\n",
              "      <td>6.6</td>\n",
              "      <td>7.0</td>\n",
              "      <td>-6.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>00:00</td>\n",
              "      <td>UTC</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>-12.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>00:00</td>\n",
              "      <td>UTC</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>-17.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Year  m  ...  Snow depth (cm) Air temperature (degC)\n",
              "0  2017  1  ...             -1.0                    0.6\n",
              "1  2017  1  ...             -1.0                   -3.9\n",
              "2  2017  1  ...              7.0                   -6.5\n",
              "3  2017  1  ...             13.0                  -12.8\n",
              "4  2017  1  ...             10.0                  -17.8\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxNt4GAoHLP7",
        "colab_type": "text"
      },
      "source": [
        "We see that the DataFrame contains eight columns, three of which are actual measured variables. Now we can refer to a column by its name:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCfDXBG4HLP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wh[\"Snow depth (cm)\"].head()     # Using the tab key can help enter long column names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAF2t-vCHLQE",
        "colab_type": "text"
      },
      "source": [
        "There are several summary statistic methods that operate on a column or on all the columns. The next example computes the mean of the temperatures over all rows of the DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QdxCZLNHLQG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wh[\"Air temperature (degC)\"].mean()    # Mean temperature"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICIumzUyHLQN",
        "colab_type": "text"
      },
      "source": [
        "We can drop some columns from the DataFrame with the `drop` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz7ds36LHLQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wh.drop(\"Time zone\", axis=1).head()    # Return a copy with one column removed, the original DataFrame stays intact"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C6h4D04HLQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wh.head()     # Original DataFrame is unchanged"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DnhFAu2HLQb",
        "colab_type": "text"
      },
      "source": [
        "In case you want to modify the original DataFrame, you can either assign the result to the original DataFrame, or use the `inplace` parameter of the `drop` method. Many of the modifying methods of the DataFrame have the `inplace` parameter.\n",
        "\n",
        "Addition of a new column works like adding a new key-value pair to a dictionary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pnc1yie4HLQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wh[\"Rainy\"] = wh[\"Precipitation amount (mm)\"] > 5\n",
        "wh.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEpK2KDuHLQn",
        "colab_type": "text"
      },
      "source": [
        "In the next sections we will systematically go through the DataFrame and its one-dimensional version: *Series*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIS0hP4MHLQq",
        "colab_type": "text"
      },
      "source": [
        "## Creation and indexing of series\n",
        "\n",
        "One can turn any one-dimensional iterable into a Series, which is a one-dimensional data structure:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-qWhxcZHLQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s=pd.Series([1, 4, 5, 2, 5, 2])\n",
        "s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPlkHn7iHLQx",
        "colab_type": "text"
      },
      "source": [
        "The data type of the elements in this Series is `int64`, integers representable in 64 bits. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQH336BgHLQ0",
        "colab_type": "text"
      },
      "source": [
        "We can also attach a name to this series:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23-Oyym-HLQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s.name = \"Grades\"\n",
        "s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evk3yYuJHLQ6",
        "colab_type": "text"
      },
      "source": [
        "The common attributes of the series are the `name`, `dtype`, and `size`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXNOkHGUHLQ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"Name: {s.name}, dtype: {s.dtype}, size: {s.size}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dmUaRnYHLQ_",
        "colab_type": "text"
      },
      "source": [
        "In addition to the values of the series, also the row indices were printed. All the accessing methods from NumPy arrays also work for the Series: indexing, slicing, masking and fancy indexing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u3C091FHLRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtSmlBycHLRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s2=s[[0,5]]                    # Fancy indexing\n",
        "print(s2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7UjezGfHLRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t=s[-2:]                    # Slicing\n",
        "t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzcWulVZHLRP",
        "colab_type": "text"
      },
      "source": [
        "Note that the indices stick to the corresponding values, they are not renumbered!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCZDJN8dHLRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t[4]                        # t[0] would give an error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoOBBpP0HLRV",
        "colab_type": "text"
      },
      "source": [
        "The values as a NumPy array are accessible via the `values` attribute:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF2RdOQnHLRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s2.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0lYsvy4HLRa",
        "colab_type": "text"
      },
      "source": [
        "And the indices are available through the `index` attribute:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4yp4WznHLRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s2.index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_jy59V_HLRh",
        "colab_type": "text"
      },
      "source": [
        "The index is not simply a NumPy array, but a data structure that allows fast access to the elements. The indices need not be integers, as the next example shows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQ9YJ4NoHLRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s3=pd.Series([1, 4, 5, 2, 5, 2], index=list(\"abcdef\"))\n",
        "s3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-dSmgpgHLRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s3.index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQRnr7hmHLRx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s3[\"b\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVN9XmFYHLR0",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "Note a special case here: if the indices are not integers, then the last index of the slice is included in the result. This is contrary to slicing with integers!\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQdPfamyHLR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s3[\"b\":\"e\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9KnEmtDHLR4",
        "colab_type": "text"
      },
      "source": [
        "It is still possible to access the series using NumPy style *implicit integer indices*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w62YA53mHLR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s3[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oedsBt2QHLR8",
        "colab_type": "text"
      },
      "source": [
        "This can be confusing though. Consider the following series:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrWu4MpRHLR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s4 = pd.Series([\"Jack\", \"Jones\", \"James\"], index=[1,2,3])\n",
        "s4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox65aS6XHLSD",
        "colab_type": "text"
      },
      "source": [
        "What do you think `s4[1]` will print? For this ambiguity Pandas offers attributes `loc` and `iloc`. The attributes `loc` always uses the explicit index, while the attribute `iloc` always uses the implicit integer index:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylKqkiW8HLSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(s4.loc[1])\n",
        "print(s4.iloc[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6neiHi8iHT2W",
        "colab_type": "text"
      },
      "source": [
        "# Pandas (continues)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxt5hgFuHT2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2rxN9foHT2s",
        "colab_type": "text"
      },
      "source": [
        "## Creation of dataframes\n",
        "\n",
        "The DataFrame is essentially a two dimensional object, and it can be created in three different ways:\n",
        "\n",
        "* out of a two dimensional NumPy array\n",
        "* out of given columns\n",
        "* out of given rows\n",
        "\n",
        "### Creating DataFrames from a NumPy array\n",
        "\n",
        "In the following example a DataFrame with 2 rows and 3 column is created. The row and column indices are given explicitly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pwxWwPXHT2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.DataFrame(np.random.randn(2,3), columns=[\"First\", \"Second\", \"Third\"], index=[\"a\", \"b\"])\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbYs7UtqHT3C",
        "colab_type": "text"
      },
      "source": [
        "Note that now both the rows and columns can be accessed using the special `Index` object:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_O9BefTHT3E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.index                            # These are the \"row names\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ROLLXVnHT3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.columns                          # These are the \"column names\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rey9MOjXHT3T",
        "colab_type": "text"
      },
      "source": [
        "If either `columns` or `index` argument is left out, then an implicit integer index will be used:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHXvY8_dHT3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2=pd.DataFrame(np.random.randn(2,3), index=[\"a\", \"b\"])\n",
        "df2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6k5EJmWHT3a",
        "colab_type": "text"
      },
      "source": [
        "Now the column index is an object similar to Python's builtin `range` type:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAXmf2LkHT3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV0pvJC9HT3j",
        "colab_type": "text"
      },
      "source": [
        "### Creating DataFrames from columns\n",
        "\n",
        "A column can be specified as a list, an NumPy array, or a Pandas' Series. The names of the columns can be given either with the `columns` parameter, or if Series objects are used, then the `name` attribute of each Series is used as the column name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHzA_eBNHT3l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s1 = pd.Series([1,2,3])\n",
        "s1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfPw5czqHT3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s2 = pd.Series([4,5,6], name=\"b\")\n",
        "s2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLK8CtwVHT3y",
        "colab_type": "text"
      },
      "source": [
        "Give the column name explicitly:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rSEcqKAHT31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(s1, columns=[\"a\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_k9-u2jHT36",
        "colab_type": "text"
      },
      "source": [
        "Use the `name` attribute of Series s2 as the column name:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec8YCfgeHT38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(s2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE76K6zaHT3_",
        "colab_type": "text"
      },
      "source": [
        "If using multiple columns, then they must be given as the dictionary, whose keys give the column names and values are the actual column content."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuHS5CX5HT4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame({\"a\": s1, \"b\": s2})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV6CCg2IHT4K",
        "colab_type": "text"
      },
      "source": [
        "### Creating DataFrames from rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_g66EpEHT4L",
        "colab_type": "text"
      },
      "source": [
        "We can give a list of rows as a parameter to the DataFrame constructor. Each row is given as a dict, list, Series, or NumPy array. If we want to give names for the columns, then either the rows must be dictionaries, where the key is the column name and the values are the elements of the DataFrame on that row and column, or else the column names must be given explicitly. An example of this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YP-X3bqBHT4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.DataFrame([{\"Wage\" : 1000, \"Name\" : \"Jack\", \"Age\" : 21}, {\"Wage\" : 1500, \"Name\" : \"John\", \"Age\" : 29}])\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3Ju2COhHT4S",
        "colab_type": "text"
      },
      "source": [
        "Or:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSI76Vb4HT4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame([[1000, \"Jack\", 21], [1500, \"John\", 29]], columns=[\"Wage\", \"Name\", \"Age\"])\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtlHzVnBHT4Z",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-warning\">Note that the order of columns is not always the same order as they were in the parameter list. In this case you can use the `columns` parameter to specify the exact order.\n",
        "\n",
        "\n",
        "In the earlier case, however, where we created DataFrames from a dictionary of columns, the order of columns should be the same as in the parameter dictionary in the recent versions of Python and Pandas.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMC6j_HEHT4a",
        "colab_type": "text"
      },
      "source": [
        "In the sense of information content the order of columns should not matter, but sometimes you want to specify a certain order to make the Frame more readable, or to make it obey some semantic meaning of column order."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL2289ZSHT4g",
        "colab_type": "text"
      },
      "source": [
        "## Accessing columns and rows of a dataframe\n",
        "\n",
        "Even though DataFrames are basically just two dimensional arrays, the way to access their elements is different from NumPy arrays. There are a couple of complications, which we will go through in this section.\n",
        "\n",
        "Firstly, the bracket notation `[]` does not allow the use of an index pair to access a single element of the DataFrame. Instead only one dimension can be specified.\n",
        "\n",
        "Well, does this dimension specify the rows of the DataFrame, like NumPy arrays if only one index is given, or does it specify the columns of the DataFrame?\n",
        "\n",
        "It depends!\n",
        "\n",
        "If an integer is used, then it specifies a column of the DataFrame in the case the **explicit** indices for the column contain that integer. In any other case an error will result. For example, with the above DataFrame, the following indexing will not work, because the explicit column index consist of the column names \"Name\" and \"Wage\" which are not integers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gq69rH6HT4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    df[0]\n",
        "except KeyError:\n",
        "    import sys\n",
        "    print(\"Key error\", file=sys.stderr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zZuGe4_HT4l",
        "colab_type": "text"
      },
      "source": [
        "The following will however work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMUrZnATHT4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[\"Wage\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlBmicmcHT4s",
        "colab_type": "text"
      },
      "source": [
        "As does the fancy indexing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcVZJH2sHT4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[[\"Wage\", \"Name\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWFqBQYtHT4x",
        "colab_type": "text"
      },
      "source": [
        "If one indexes with a slice or a boolean mask, then the **rows** are referred to. Examples of these:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2oju8_XHT4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[0:1]                           # slice"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4uyATteHT42",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[df.Wage > 1200]               # boolean mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yD7ZLtpHT45",
        "colab_type": "text"
      },
      "source": [
        "If some of the above calls return a Series object, then you can chain the bracket calls to get a single value from the DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gMlnfcbHT45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[\"Wage\"][1]                    # Note order of dimensions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b03D1rZHT49",
        "colab_type": "text"
      },
      "source": [
        "But there is a better way to achieve this, which we will see in the next section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQOWSGAbHT5F",
        "colab_type": "text"
      },
      "source": [
        "## Alternative indexing and data selection\n",
        "\n",
        "If the explanation in the previous section sounded confusing or ambiguous, or if you didn't understand a thing, you don't have to worry.\n",
        "\n",
        "There is another way to index Pandas DataFrames, which\n",
        "\n",
        "* allows use of index pairs to access a single element\n",
        "* has the same order of dimensions as NumPy: first index specifies rows, second columns\n",
        "* is not ambiguous about implicit or explicit indices\n",
        "\n",
        "Pandas DataFrames have attributes `loc` and `iloc` that have the above qualities.\n",
        "You can use `loc` and `iloc` attributes and forget everything about the previous section. Or you can use these attributes\n",
        "and sometimes use the methods from the previous section as shortcuts if you understand them well.\n",
        "\n",
        "The difference between `loc` and `iloc` attributes is that the former uses explicit indices and the latter uses the implicit integer indices. Examples of use:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGoSD0NNHT5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.loc[1, \"Wage\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G56OjgWrHT5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.iloc[-1,-1]             # Right lower corner of the DataFrame"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTj8WbRpHT5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.loc[1, [\"Name\", \"Wage\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSciu6p1HT5T",
        "colab_type": "text"
      },
      "source": [
        "With `iloc` everything works like with NumPy arrays: indexing, slicing, fancy indexing, masking and their combinations. With `loc` it is the same but now the names in the explicit indices are used for specifying rows and columns. Make sure your understand why the above examples work as they do!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce9Otb9OHT5W",
        "colab_type": "text"
      },
      "source": [
        "## Summary statistics\n",
        "\n",
        "The summary statistic methods work in a similar way as their counter parts in NumPy. By default, the aggregation is done over columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jvx0OF9HT5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wh = pd.read_csv(\"https://raw.githubusercontent.com/smabb/p/master/data/temp.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOFMUYlFHT5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wh2 = wh.drop([\"Year\", \"m\", \"d\"], axis=1)  # taking averages over these is not very interesting\n",
        "wh2.mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stG8bu4wHT5d",
        "colab_type": "text"
      },
      "source": [
        "The `describe` method of the `DataFrame` object gives different summary statistics for each (numeric) column. The result is a DataFrame. This method gives a good overview of the data, and is typically used in the exploratory data analysis phase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUDa7za6HT5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wh.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKLPnx6cHT50",
        "colab_type": "text"
      },
      "source": [
        "## Missing data\n",
        "\n",
        "You may have noticed something strange in the output of the `describe` method. First, the minimum value in both precipitation and snow depth fields is -1. The special value -1 means that on that day there was absolutely no snow or rain, whereas the value 0 might indicate that the value was close to zero. Secondly, the snow depth column has count 358, whereas the other columns have count 365, one measurement/value for each day of the year. How is this possible? Every field in a DataFrame should have the same number of rows. Let's use the `unique` method of the Series object to find out, which different values are used in this column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NflnOdg6HT51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wh[\"Snow depth (cm)\"].unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-By6rHCHT52",
        "colab_type": "text"
      },
      "source": [
        "The `float` type allows a special value `nan` (Not A Number), in addition to normal floating point numbers. This value can represent the result from an illegal operation. For example, the operation 0/0 can either cause an exception to occur or just silently produce a `nan`. In Pandas `nan` can be used to represent a missing value. In the weather DataFrame the `nan` value tells us that the measurement from that day is not available, possibly due to a broken measuring instrument or some other problem.\n",
        "\n",
        "Note that only float types allow the `nan` value (in Python, NumPy or Pandas). So, if we try to create an integer series with missing values, its dtype gets promoted to `float`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSUTugvPHT53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.Series([1,3,2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jf-GHd0kHT55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.Series([1,3,2, np.nan])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ao5V4FrHHT58",
        "colab_type": "text"
      },
      "source": [
        "For non-numeric types the special value `None` is used to denote a missing value, and the dtype is promoted to `object`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-flsOh-jHT58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.Series([\"jack\", \"joe\", None])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCh7K2FXHT6A",
        "colab_type": "text"
      },
      "source": [
        "Pandas excludes the missing values from the summary statistics, like we saw in the previous section. Pandas also provides some functions to handle missing values.\n",
        "\n",
        "The missing values can be located with the `isnull` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyC23g77HT6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wh.isnull()      # returns a boolean mask DataFrame"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhLd_dPBHT6E",
        "colab_type": "text"
      },
      "source": [
        "This is not very useful as we cannot directly use the mask to index the DataFrame. We can, however, combine it with the `any` method to find out all the rows that contain at least one missing value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzfeUQIjHT6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wh[wh.isnull().any(axis=1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsgMcC62HT6K",
        "colab_type": "text"
      },
      "source": [
        "The `notnull` method works conversively to the `isnull` method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPus9l0jHT6K",
        "colab_type": "text"
      },
      "source": [
        "The `dropna` method of a DataFrame drops columns or rows that contain missing values from the DataFrame, depending on the `axis` parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUcYKNCSHT6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wh.dropna().shape   # Default axis is 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tcPpdhXHT6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wh.dropna(axis=1).shape # Drops the columns containing missing values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S12ngYQhHT6T",
        "colab_type": "text"
      },
      "source": [
        "The `how` and `thresh` parameters of the `dropna` method allow one to specify how many values need to be missing in order for the row/column to be dropped.\n",
        "\n",
        "The `fillna` method allows to fill the missing values with some constant or interpolated values. The `method` parameter can be:\n",
        "\n",
        "* `None`: use the given positional parameter as the constant to fill missing values with\n",
        "* `ffill`: use the previous value to fill the current value\n",
        "* `bfill`: use the next value to fill the current value\n",
        "\n",
        "For example, for the weather data we could use forward fill"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AroImDeRHT6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wh = wh.fillna(method='ffill')\n",
        "wh[wh.isnull().any(axis=1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWEyi7oRHT6W",
        "colab_type": "text"
      },
      "source": [
        "The `interpolate` method, which we will not cover here, offers more elaborate ways to interpolate the missing values from their neighbouring non-missing values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOX3-hzSHT6a",
        "colab_type": "text"
      },
      "source": [
        "## Converting columns from one type to another\n",
        "\n",
        "There are several ways of converting a column to another type. For converting single columns (a Series) one can use the `pd.to_numeric` function or the `map` method. For converting several columns in one go one can use the `astype` method. We will give a few examples of use of these methods/functions. For more details, look from the Pandas documentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wc7bXYS8HT6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.Series([\"1\",\"2\"]).map(int)                           # str -> int"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVpRzO9rHT6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.Series([1,2]).map(str)                               # int -> str"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVo3s9crHT6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.to_numeric(pd.Series([1,1.0]), downcast=\"integer\")   # object -> int"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1DHmL_8HT6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.to_numeric(pd.Series([1,\"a\"]), errors=\"coerce\")      # conversion error produces Nan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk18bqD5HT6j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.Series([1,2]).astype(str)                            # works for a single series"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oiNCJmeHT6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame({\"a\": [1,2,3], \"b\" : [4,5,6], \"c\" : [7,8,9]})\n",
        "print(df.dtypes)\n",
        "print(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQy7_Ab0HT6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.astype(float)                       # Convert all columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTPRL9XqHT6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2 = df.astype({\"b\" : float, \"c\" : str})    # different types for columns\n",
        "print(df2.dtypes)\n",
        "print(df2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-Sk6xoWHT6y",
        "colab_type": "text"
      },
      "source": [
        "## String processing\n",
        "\n",
        "If the elements in a column are strings, then the vectorized versions of Python's string processing methods are available. These are accessed through the `str` attribute of a Series or a DataFrame. For example, to capitalize all the strings of a Series, we can use the `str.capitalize` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHEKK24WHT6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "names = pd.Series([\"donald\", \"theresa\", \"angela\", \"vladimir\"])\n",
        "names.str.capitalize()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SN8RP9TEHT61",
        "colab_type": "text"
      },
      "source": [
        "One can find all the available methods by pressing the tab key after the text `names.str.` in a Python prompt. Try it in below cell!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRkN6zA7HT62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#names.str."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJcehdh2HT64",
        "colab_type": "text"
      },
      "source": [
        "We can split a column or Series into several columns using the `split` method. For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLTnh5wyHT64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_names = pd.Series([\"Donald Trump\", \"Theresa May\", \"Angela Merkel\", \"Vladimir Putin\"])\n",
        "full_names.str.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsZ9FVOVHT66",
        "colab_type": "text"
      },
      "source": [
        "This is not exactly what we wanted: now each element is a list. We need to use the `expand` parameter to split into columns:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyfP8mGUHT66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_names.str.split(expand=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fgijQ7LHT6_",
        "colab_type": "text"
      },
      "source": [
        "## Additional information\n",
        "\n",
        "We covered subsetting of DataFrames with the indexers `[]`, `.loc[]`, and `.iloc[]` quite concisely.\n",
        "For a more verbose explanation, look at the [tutorials at Dunder Data](https://medium.com/dunder-data/pandas-tutorials/home). Especially, the problems with chained indexing operators (like `df[\"a\"][1]`) are explained well there (tutorial 4), which we did not cover at all. As a rule of thumb: one should avoid chained indexing combined with assignment! See [Pandas documentation](http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#why-does-assignment-fail-when-using-chained-indexing)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRWZUValHeQg",
        "colab_type": "text"
      },
      "source": [
        "# Pandas (continues)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWO7K45eHeQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loV2GYoiHeQ1",
        "colab_type": "text"
      },
      "source": [
        "## Catenating datasets\n",
        "\n",
        "We already saw in the NumPy section how we can catenate arrays along an axis: `axis=0` catenates vertically and `axis=1` catenates horizontally, and so on. With the DataFrames of Pandas it works similarly except that the row indices and the column names require extra attention. Also note a slight difference in the name: `np.concatenate` but `pd.concat`.\n",
        "\n",
        "Let's start by considering catenation along the axis 0, that is, vertical catenation. We will first make a helper function to easily create DataFrames for testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHckZ3bFHeQ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def makedf(cols, ind):\n",
        "    data = {c : [str(c) + str(i) for i in ind] for c in cols}\n",
        "    return pd.DataFrame(data, ind)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hk_eoNH0HeRI",
        "colab_type": "text"
      },
      "source": [
        "Next we will create some example DataFrames:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6A1X3sXHeRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a=makedf(\"AB\", [0,1])\n",
        "a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fcx9AZeHeRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b=makedf(\"AB\", [2,3])\n",
        "b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQA-j3BFHeRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c=makedf(\"CD\", [0,1])\n",
        "c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ai2pVMrgHeRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d=makedf(\"BC\", [2,3])\n",
        "d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHKaxXFIHeRt",
        "colab_type": "text"
      },
      "source": [
        "In the following simple case, the `concat` function works exactly as we expect it would:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_3THIRTHeRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.concat([a,b])   # The default axis is 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INgjqFvSHeR8",
        "colab_type": "text"
      },
      "source": [
        "The next, however, will create duplicate indices:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8lEPCHPHeSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r=pd.concat([a,a])\n",
        "r"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEu4_qDNHeSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r.loc[0,\"A\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm0lTGSvHeSO",
        "colab_type": "text"
      },
      "source": [
        "This is not usually what we want! There are three solutions to this. Firstly, deny creation of duplicated indices by giving the `verify_integrity` parameter to the `concat` function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxzqcmIHHeSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    pd.concat([a,a], verify_integrity=True)\n",
        "except ValueError as e:\n",
        "    import sys\n",
        "    print(e, file=sys.stderr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4QiZ5E_HeSY",
        "colab_type": "text"
      },
      "source": [
        "Secondly, we can ask for automatic renumbering of rows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyIaoXxLHeSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.concat([a,a], ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nVuh2JaHeSk",
        "colab_type": "text"
      },
      "source": [
        "Thirdly, we can ask for *hierarchical indexing*. The indices can contain multiple levels, but on this course we don't consider hierarchical indices in detail. Hierarchical indices can make a two dimensional array to work like higher dimensional array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ds-5xPxHeSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r2=pd.concat([a,a], keys=['first', 'second'])\n",
        "r2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCb4zSbpHeSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r2[\"A\"][\"first\"][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRGhiaNEHeSu",
        "colab_type": "text"
      },
      "source": [
        "Everything works similarly, when we want to catenate horizontally:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvq_jbBAHeSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.concat([a,c], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akqmcTcmHeS1",
        "colab_type": "text"
      },
      "source": [
        "We have so far assumed that when concatenating vertically the columns of both DataFrames are the same, and when joining horizontally the indices are the same. This is, however, not required:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UNt1EwZHeS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.concat([a,d], sort=False)    # sort option is used to silence a deprecation message"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kv0fXCeZHeS7",
        "colab_type": "text"
      },
      "source": [
        "It expanded the non-existing cases with `NaN`s. This method is called an *outer join*, which forms the union of columns in the two DataFrames. The alternative is *inner join*, which forms the intersection of columns:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMJWncDYHeS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.concat([a,d], join=\"inner\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cGQJCsoHeTB",
        "colab_type": "text"
      },
      "source": [
        "## Merging dataframes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IJ6W42HHeTD",
        "colab_type": "text"
      },
      "source": [
        "Merging combines two DataFrames based on some common field."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0v38TAakHeTD",
        "colab_type": "text"
      },
      "source": [
        "Let's recall the earlier DataFrame about wages and ages of persons:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPipjHd_HeTH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame([[1000, \"Jack\", 21], [1500, \"John\", 29]], columns=[\"Wage\", \"Name\", \"Age\"])\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjv3AnfvHeTK",
        "colab_type": "text"
      },
      "source": [
        "Now, create a new DataFrame with the occupations of persons:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJgkLSeCHeTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2 = pd.DataFrame({\"Name\" : [\"John\", \"Jack\"], \"Occupation\": [\"Plumber\", \"Carpenter\"]})\n",
        "df2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7F2AX_fHeTP",
        "colab_type": "text"
      },
      "source": [
        "The following function call will merge the two DataFrames on their common field, and, importantly, will keep the indices *aligned*. What this means is that even though the names are listed in different order in the two frames, the merge will still give correct result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EExjxclyHeTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.merge(df, df2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaarefbNHeTT",
        "colab_type": "text"
      },
      "source": [
        "This was an example of a simple one-to-one merge, where the keys in the `Name` columns had 1-to-1 correspondence. Sometimes not all the keys appear in both DataFrames:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3dvLta2HeTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df3 = pd.concat([df2, pd.DataFrame({ \"Name\" : [\"James\"], \"Occupation\":[\"Painter\"]})], ignore_index=True)\n",
        "df3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2i0TTetHeTY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.merge(df, df3)                # By default an inner join is computed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjnUk7wOHeTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.merge(df, df3, how=\"outer\")   # Outer join"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp7tVUwUHeTl",
        "colab_type": "text"
      },
      "source": [
        "Also, many-to-one and many-to-many relationships can occur in merges:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21fE5HzpHeTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "books = pd.DataFrame({\"Title\" : [\"War and Peace\", \"Good Omens\", \"Good Omens\"] , \n",
        "                      \"Author\" : [\"Tolstoi\", \"Terry Pratchett\", \"Neil Gaiman\"]})\n",
        "books"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhZgBjCAHeTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "collections = pd.DataFrame([[\"Oodi\", \"War and Peace\"],\n",
        "                           [\"Oodi\", \"Good Omens\"],\n",
        "                           [\"Pasila\", \"Good Omens\"],\n",
        "                           [\"Kallio\", \"War and Peace\"]], columns=[\"Library\", \"Title\"])\n",
        "collections"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNYHegUtHeT0",
        "colab_type": "text"
      },
      "source": [
        "All combinations with matching keys (`Title`) are created:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWnphVhtHeT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "libraries_with_books_by = pd.merge(books, collections)\n",
        "libraries_with_books_by"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuDP5Z9THeUC",
        "colab_type": "text"
      },
      "source": [
        "## Aggregates and groupings\n",
        "\n",
        "Let us use again the weather dataset. First, we make the column names a bit more uniform and concise. For example the columns `Year`, `m`, and `d` are not uniformly named.\n",
        "\n",
        "We can easily change the column names with the `rename` method of the DataFrame. Note that we cannot directly change the index `wh.columns` as it is immutable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC-Ncdh5HeUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wh = pd.read_csv(\"https://raw.githubusercontent.com/smabb/p/master/data/temp.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcM2poefHeUF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wh3 = wh.rename(columns={\"m\": \"Month\", \"d\": \"Day\", \"Precipitation amount (mm)\" : \"Precipitation\", \n",
        "                         \"Snow depth (cm)\" : \"Snow\", \"Air temperature (degC)\" : \"Temperature\"})\n",
        "wh3.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TSKEbYmHeUM",
        "colab_type": "text"
      },
      "source": [
        "Pandas has an operation that splits a DataFrame into groups, performs some operation on each of the groups, and then combines the result from each group into a resulting DataFrame. This split-apply-combine functionality is really flexible and powerful operation. In Pandas you start by calling the `groupby` method, which splits the DataFrame into groups. In the following example the rows that contain measurements from the same month belong to the same group:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-q4G9vaMHeUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "groups = wh3.groupby(\"Month\")\n",
        "groups"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmkAfJwlHeUT",
        "colab_type": "text"
      },
      "source": [
        "Nothing happened yet, but the `groupby` object knows how the division into groups is done. This is called a lazy operation. We can query the number of groups in the `groupby` object:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyNRReiIHeUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(groups)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-9f3JoVHeUZ",
        "colab_type": "text"
      },
      "source": [
        "We can iterate through all the groups:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YskEZqi6HeUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for key, group in groups:\n",
        "    print(key, len(group))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bu-Eo9m4HeUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "groups.get_group(2)                 # Group with index two is February"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXi1ZfyrHeUf",
        "colab_type": "text"
      },
      "source": [
        "The `groupby` object functions a bit like a DataFrame, so some operations which are allowed for DataFrames are also allowed for the `groupby` object. For example, we can get a subset of columns:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9u3mXjAHeUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "groups[\"Temperature\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uUgR8E3HeUk",
        "colab_type": "text"
      },
      "source": [
        "For each DataFrame corresponding to a group the Temperature column was chosen. Still nothing was shown, because we haven't applied any operation on the groups."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRERi3QQHeUk",
        "colab_type": "text"
      },
      "source": [
        "The common methods also include the aggregation methods. Let's try to apply the `mean` aggregation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz8E5C7KHeUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "groups[\"Temperature\"].mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "co0-2VtPHeUt",
        "colab_type": "text"
      },
      "source": [
        "Now what happened was that after the mean aggregation was performed on each group, the results were automatically combined into a resulting DataFrame. Let's try some other aggregation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEcLSC-qHeUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "groups[\"Precipitation\"].sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlh4cdFxHeUz",
        "colab_type": "text"
      },
      "source": [
        "Ok, the -1.0 values in the Precipitation field are causing trouble here, let's convert them to zeros:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCyR6S4jHeU0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wh4 = wh3.copy()\n",
        "wh4.loc[wh4.Precipitation == -1, \"Precipitation\"] = 0\n",
        "wh4.loc[wh4.Snow == -1, \"Snow\"] = 0\n",
        "wh4.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzT5_WpFHeU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wh4.groupby(\"Month\")[\"Precipitation\"].sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pctJhJG6HeU8",
        "colab_type": "text"
      },
      "source": [
        "### Other ways to operate on groups\n",
        "\n",
        "The aggregations are not the only possible operations on groups. The other possibilities are filtering, transformation, and application.\n",
        "\n",
        "In **filtering** some of the groups can be filtered out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tgvk5atuHeU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def myfilter(df):                                     # The filter function must return a boolean value\n",
        "    return df[\"Precipitation\"].sum() >= 150\n",
        "\n",
        "wh4.groupby(\"Month\").filter(myfilter)                 # Filter out months with total precipitation less that 150 mm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjpMhY8eHeU-",
        "colab_type": "text"
      },
      "source": [
        "In a **transformation** each group's DataFrame is manipulated in a way that retains its shape. An example of centering values, so that the deviations from the monthly means are shown:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L73DahWtHeU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.concat([wh4.iloc[:, 0:3], \n",
        "           wh4.groupby(\"Month\")[[\"Precipitation\", \"Snow\", \"Temperature\"]].transform(lambda x : x - x.mean())], \n",
        "          axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUtx3gBRHeVC",
        "colab_type": "text"
      },
      "source": [
        "The **apply** method is very generic and only requires that for each group's DataFrame the given function returns a DataFrame, Series, or a scalar. In the following example, we sort within each group by the temperature:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDFsvYokHeVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wh4.groupby(\"Month\").apply(lambda df : df.sort_values(\"Temperature\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfUfefoqHeVN",
        "colab_type": "text"
      },
      "source": [
        "## Time series\n",
        "\n",
        "If a measurement is made at certain points in time, the resulting values with their measurement times is called a time series. In Pandas a Series whose index consists of dates/times is a time series."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XT2fS1WdHeVO",
        "colab_type": "text"
      },
      "source": [
        "Let's make a copy of the DataFrame that we can mess with:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6MXexAQHeVO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wh2 = wh3.copy()\n",
        "wh2.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPqERlOAHeVT",
        "colab_type": "text"
      },
      "source": [
        "The column names `Year`, `Month`, and `Day` are now in appropriate form for the `to_datetime` function. It can convert these fields into a timestamp series, which we will add to the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NSAYEl_HeVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wh2[\"Date\"] = pd.to_datetime(wh2[[\"Year\", \"Month\", \"Day\"]])\n",
        "wh2.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7yrFn2VHeVf",
        "colab_type": "text"
      },
      "source": [
        "We can now drop the useless fields:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aeA1_7zHeVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wh2=wh2.drop(columns=[\"Year\", \"Month\", \"Day\"])\n",
        "wh2.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUgHRxdFHeVl",
        "colab_type": "text"
      },
      "source": [
        "The following method call will set the Date field as the index of the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4K9Mu4FHeVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wh2 = wh2.set_index(\"Date\")\n",
        "wh2.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFFPda1yHeVp",
        "colab_type": "text"
      },
      "source": [
        "We can now easily get a set of rows using date slices:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNbHZ08dHeVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wh2[\"2017-01-15\":\"2017-02-03\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMouUg33HeVs",
        "colab_type": "text"
      },
      "source": [
        "By using the `date_range` function even more complicated sets can be formed. The following gets all the Mondays of July:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_asnLFaHeVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r=pd.date_range(\"2017-07-01\", \"2017-07-31\", freq=\"w-mon\")\n",
        "r"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_ZnyjqiHeVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wh2.index.difference(r)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O97rm4j7HeVv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wh2.loc[r,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52esFgPQHeVy",
        "colab_type": "text"
      },
      "source": [
        "The following finds all the business days (Monday to Friday) of July:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEGo4w-NHeVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.date_range(\"2017-07-01\", \"2017-07-31\", freq=\"b\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdC1ANNAHeV1",
        "colab_type": "text"
      },
      "source": [
        "We can get a general idea about the `Temperature` column by plotting it. Note how the index time series is shown nicely on the x-axis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hf7fUDIHeV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "wh2[\"Temperature\"].plot();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og5wMvyRHeV4",
        "colab_type": "text"
      },
      "source": [
        "The graph looks a bit messy at this level of detail. We can smooth it by taking averages over a sliding window of length 30 days:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP2KLxm8HeV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rolling = wh2.Temperature.rolling(30, center=True)\n",
        "rolling"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqRuNpOsHeV7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.DataFrame({\"Temperature\" : wh2.Temperature, \"Rolling mean\" : rolling.mean()})\n",
        "data.plot();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSLyA8HsHeV-",
        "colab_type": "text"
      },
      "source": [
        "## Additional information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5Swg-L9HeV_",
        "colab_type": "text"
      },
      "source": [
        "[Pandas cheat sheet](https://github.com/pandas-dev/pandas/blob/master/doc/cheatsheet/Pandas_Cheat_Sheet.pdf) Summary of most important Pandas' functions and methods.\n",
        "\n",
        "Read the article [Tidy Data](https://www.jstatsoft.org/article/view/v059i10/v59i10.pdf). The article uses the statistical software R as an example, but the ideas are relevant in general. Pandas operations maintain data in the tidy format.\n",
        "\n",
        "Pandas handles only one dimensional data (Series) and two dimensional data (DataFrame). While you can use [hierarchical indices](http://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html#hierarchical-indexing-multiindex) to simulate higher dimensional arrays, you should use the [xarray](http://xarray.pydata.org/en/stable/index.html) library, if you need proper higher-dimensional arrays with labels. It is basically a cross between NumPy and Pandas.\n",
        "\n"
      ]
    }
  ]
}